[{"authors":["jim"],"categories":null,"content":"Dr. Jim Webber is Neo4j’s Chief Scientist and Visiting Professor at Newcastle University. At Neo4j, Jim works on fault-tolerant graph databases and co-wrote Graph Databases (1st and 2nd editions, O’Reilly) and Graph Databases for Dummies (Wiley).\nPrior to Neo4j, Jim worked on fault-tolerant distributed systems. First at Newcastle University startup Arjuna and then for a variety of clients for global consulting firm ThoughtWorks. Along the way Jim co-authored the books REST in Practice (O\u0026rsquo;Reilly) and Developing Enterprise Web Services - An Architect’s Guide (Prentice Hall).\nJim is active in the software development and database research communities, presenting regularly around the world. His blog is located at https://jimwebber.org and he tweets sometimes at @jimwebber.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"76887015496b6bc3e7f2107145ecc1f8","permalink":"/author/dr.-jim-webber/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dr.-jim-webber/","section":"authors","summary":"Dr. Jim Webber is Neo4j’s Chief Scientist and Visiting Professor at Newcastle University. At Neo4j, Jim works on fault-tolerant graph databases and co-wrote Graph Databases (1st and 2nd editions, O’Reilly) and Graph Databases for Dummies (Wiley).","tags":null,"title":"Dr. Jim Webber","type":"authors"},{"authors":[],"categories":[],"content":"Motivation For the last few years, I\u0026rsquo;ve been working with Paul Ezhilchelvan, Isi Mitrani, and Jack Waudby from Newcastle University. We\u0026rsquo;ve been thinking about consistency models specifically for graph databases, trying to understand whether consistency models for graph databases are different from other database types and how we can preserve correctness while still being useful for demanding production systems. This post is a summary of the work we\u0026rsquo;ve done for a technical generalist audience, and I hope you enjoy reading it.\nThe work has been both fun and fruitful. Our focus has been on edge-distributed graph databases where the relationships between nodes logically cross the network when those nodes reside on different servers.\n  Nodes representing Karl and Rosa are on different servers, and there is a logical FOLLOWS relationship/edge between them which crosses the network.   We\u0026rsquo;ve identified an important safety property called Reciprocal Consistency. Put simply, if the record that stores the Karl node on Server 1 has an entry for an outgoing FOLLOWS relationship to the Rosa node on Server 2 then the record representing the Rosa node should have an entry for an incoming relationship from the Karl node. The nodes at the head and tail of the relationship hold reciprocal information, hence are reciprocaly consistent.\nMaintaining reciprocal consistency isn\u0026rsquo;t well addressed in the literature. The closest analogue we can find are foreign key constraints in relational databases. Some distributed relational databases, like YugabyteDB, preserve foreign key constraints by using strongly consistent (serializable) transaction protocols only where strictly necessary for correctiness and using less expensive (snapshot) protocols everywhere else.\nIn the case of graph databases, these kind of foreign key constraints aren\u0026rsquo;t a special case. Relationships in a graph are plentiful and the chance of any individual relationship being distributed across servers (or shards) is reasonably high at around 30% given a good partitioning algorithm like Hugo Firth\u0026rsquo;s Taper.\nTo preserve correctness in an edge-distributed graph database we could choose to fallback to a conservative transaction protocol (like two-phase commit), but we know that will harm performance. If we use cheaper models like eventual consistency, we might lose reciprocal consistency. In fact we found that eventually-consistent edge-distributed graph databases will corrupt data under normal operation to the extent that a whole database will be rendered useless in a short period of time.\nBut this article isn\u0026rsquo;t really about eventual consistency. Though we started with eventual consistency in mind, it turns out to lead to a more fundamental question: if eventual consistency leads to corruption, are so-called strongly consistent systems immune? Given that question, we\u0026rsquo;ve lately focussed on systems designs that claim to be strongly consistent (using words like ACID) but which nonetheless fail to uphold reciprocal consistency causing corruption in normal operation.\nCorruption by design is a shocking (and fascinating) result in a strongly consistent system. I\u0026rsquo;ll dig much deeper into the root cause in a moment. But first a little history as to how we found ourselves here.\nThe trouble with eventually-consistent graph databases A few years ago when the (now abandoned) TitanDB was launched I recall thinking that its design was problematic from a safety and performance viewpoint. For performance, the problems were around locality. TitanDB spreads bits of the graph across servers to boost write performance, with less regard to how the data would be queried - the expectation is that most queries will have to cross servers to complete, adding complexity and latency. But a slow database is might still be a safe database, but TitanDB wasn\u0026rsquo;t safe - in allowing uncoordinated writes across servers, race conditions could occur which would leave the database in inconsistent state.\nThis is partially understandable. The primary motivation for TitanDB, its successor JanusGraph, and other similar graph databses was scalability. I think it was a rational decision: the market places a premium on scalability and scalability non-trivial if you also want safety and performance. What I think also helped is that the market tended to assume that features like performance and safety were innately part of anything called a database.\nOf course, scale does not necessarily mean high-performance in absolute terms. Scale means you can add more computers to a system and perform more processing relative to fewer computers in the same system. It\u0026rsquo;s often why Neo4j on a laptop can humiliate scale-out graph databases on many powerful servers.\nIn our work we were less concerned about performance, and much more about the safety properties of eventually-consistent graph databases. You probably already know that eventual consistency provides a straightforward guarantee for a single replica set that it will converge to the same value eventually (perhaps even before the next read in good systems). The value converged upon is influenced by the chosen concurrency control mechanisms (e.g. Last Writer Wins versus Logical Clocks etc), but nonetheless the guarantee is strictly for one replica set/shard. This might be fine for some data types, but we strongly suspected that it is not fine for edge-distributed graphs. Spoiler: it isn\u0026rsquo;t.\nSources of corruption in eventually-consistent graph databases Eventually consistent databases scale because they avoid costly/centralised operations. Because of that, there\u0026rsquo;s no coordination/ordering across the database, just local concurrency controls on each server. The concurrency control might be simple and cheap like Last-Writer-Wins (LWW) or it might be a fancy merge function, but whatever mechanism is chosen, it acts locally on each server. Fortunately anti-entropy functions are available on most databases so that divergence between replicas within a set can be salvaged (though such functions tend not to be aggresively used in case they inhibit performance).\nEven with anti-entropy functionality, with an eventually consistent distributed graph database there are two primary sources of potential corruption:\n The current transaction happens to read from a replica which is stale and uses that stale data to for updates. This is more complex than the same situation in a KV, document, or column store because graph database queries touch arbitrary keys and so undoing logical corruption is impractical and typically impossible. However, this is solvable with approaches like quorum reads though they will slow down the operation of the database considerably. Two transactions contend on a single relationship/egde which happens to span replica sets (shards from here on) and are applied in a mutually inconsistent order. This is also solvable but requires some functionality to impose ordering, which is expensive completely undermines eventual consistency, and so nobody does this because it implies transactions.  The TitanDB team were rigorous enough to call out this problem, but the language they used downplays its signficance. The documentation uses phrases like \u0026ldquo;temporary inconsistency\u0026rdquo; rather than \u0026ldquo;corruption that might be repaired, but might also cause further irreperable corruption\u0026rdquo; and \u0026ldquo;half edges\u0026rdquo; rather than \u0026ldquo;corrupted edge records\u0026rdquo;. While I don\u0026rsquo;t think this mollifying language has directly lead to a slew of copycat databases, it certainly set a tone for ignoring safety properties (which is still followed by other databases in the family).\nQuantifying corruption in no-fault systems It\u0026rsquo;s an unsettling feeling to be looking for data corruption for databases operating in a fault-free environment. The very word \u0026ldquo;database\u0026rdquo; closely associated with the notion of safety. We had seen tacit admission of a possible technical error case from the TitanDB developers, but we didn\u0026rsquo;t know if it would be a problem im real systems, and waiting around in real time to see if corruption arose didn\u0026rsquo;t seemed expensive in time and cloud compute bills.\nInstead, I asked academics Paul Ezhilchelvan and Isi Mitrani for help. In a way it was a kind of homecoming for me, being able to work with two of the lecturers who\u0026rsquo;d taught me Computer Science as an undergraduate (a gruelling task no doubt). On that note I\u0026rsquo;ll point out that any errors or misunderstandings are mine alone since Paul and Isi are outstanding computer scientists.\nWe decided to model the effects of failing reciprocal consistency for a busy, long-lived, eventually-consistent distributed graph database. We chose a scale-free graph as the basis for our model, and informally thought of it a social network with a few nodes representing popular celebrities with very high degree, the next few layers with increasing freqency and decreasing degree representing various levels of sub-celebrity influence, scaling all the down to many nodes with very low degree representing most ordinary people.\nOur model treats a graph database as a collection of replica sets or shards each holding some fraction of the overall graph. It has to be distributed, of course, so that we can elicit the mechanical failure modes of distrbuted-edge partitioned graph databases. In our model, usually two connected nodes will be held on a single shard, and by implication so to will the relationships joining them be stored on that shard. However according to research on graph partitioning algorithms by my colleague Hugo Firth, a good partitioning still results in around 30% of relationships connecting nodes that are hosted on different shards - these relationships are said to be distributed.\nThe model allows for write-after-stale-read from a replica as one source of corruption, and also allowed mutually out of order update processing for relationship records that span shards as the other primary source of corruption. Out of order updates have a chance of being overwritten correctly before they\u0026rsquo;re ever seen, but they also have a chance of the stale side of the relationship being read and used to compute future incorrect updates from where it becomes impossible to repair the data in the general case.\nIn our model, relationship records which cross shards are physically implemented as a two reciprocal records on each shard (a common real-world implementation strategy). That is if shard A has a node representing Rosa with an outgoing FOLLOWS relationship to a node representing Karl on shard B, then the Karl node on shard B should have an incoming FOLLOWS from Rosa on shard A.\n// TODO: picture needed\nEqually any properties on that relationship must be identical whether the relationship is traversed head to tail or tail to head.\n// TODO: picture needed\nWe term this reciprocal consistency and it is an invariant on the database so that data can be safely stored. Any deviation from a reciprocally consistent state is corruption, and that corruption has a chance to spread through the graph.\nUsing the model, we showed that for a billions-node scale-free graph and ~10,000 TPS and with some conservative estimates for the likelihood of transactions being applied mutually out of order, that the system would be garbage (defined as 10% corruption) in around 12-18 months.\nSince the model was computationally expensive (many hours of compute time needed for each minor parameter change) we used it to calibrate a computationally cheap numerical approximation which you can parameterise to see how your eventually consistent graph database might behave in production.\nIt\u0026rsquo;s not about eventual consistency, it\u0026rsquo;s about uncoordinated updates Our suspicion going into this work was that eventual consistency was the problematic factor. Clearly if you can read a stale value and write back to the database based on that stale value, you\u0026rsquo;re going to get logical corruption. But that can be mitigated, albeit at a cost in competent eventually consistent systems.\nSo, our focus on eventual consistency wasn\u0026rsquo;t wrong, but it wasn\u0026rsquo;t quite right either. In fact we found that the consistency model for how a replication within a shard was less important than how updates are delivered across shards.\nWith hindsight, eventually consistent databases were obvious because they have no coordination at all and so by implication no consistent ordering of arrival/processing by receiving shards. What\u0026rsquo;s surprising though is if we make the model more generous, we still get corruption.\nLet\u0026rsquo;s assume that the replicas in a shard converge immediately and that faults can never occur. This is an impossible, magical algorithm for replication, and still the database would suffer corruption.\nThe problem is of reciprocal consistency being undermined by race conditions in the presence of concurrent contended transactions. While we have fewer opportunities to read stale data in a single shard (because we assumed instant convergence), it\u0026rsquo;s still possible that transactions will be delivered mutually out of order to a pair of shards.\nLet\u0026rsquo;s play this out. Consider two transactions T1 and T2 which both update a common cross-shard relationship R in some mutally incompatible manner. Drawing on the TitanDB example, this could be where one transaction tries to delete R while the other tries to update it.\nThere are two ways these transactions can achieve a consistent outcome and two ways in which they won\u0026rsquo;t, and since we don\u0026rsquo;t have any coordination logic to impose an ordering (on the basis that it inhibits scalability) then we have to rely on natural arrival order.\n   Shard 1 Shard 2 Consistent     T1-\u0026gt;T2 T1-\u0026gt;T2 Yes   T2-\u0026gt;T1 T2-\u0026gt;T1 Yes   T2-\u0026gt;T1 T1-\u0026gt;T2 Maybe   T1-\u0026gt;T2 T2-\u0026gt;T1 Maybe    Corruption can occur when T1 and T2 are processed in different orders on different shards for operations that don\u0026rsquo;t commute. In such cases reciprocal consistency will have been violated.\nFor example, if T1 adds property since:2010 to the FOLLOWS relationship between Rosa and Karl while concurrently T2 adds property since:2015 to the FOLLOWS relationship between Rosa and Karl, then we have a problem. Ideally we\u0026rsquo;d like the values to converge to one of these, but they never will because there is no protocol to enforce consistency across the shards.\n   Shard 1 (T1-\u0026gt;T2) Shard 2 (T2-\u0026gt;T1)     (Rosa)-[:FOLLOWS {since:2010}]-\u0026gt;(remote)  (remote)-[:FOLLOWS {since:2015}]-\u0026gt;(Karl)    This is a type of non-deterministic corruption where one shard holds the \u0026ldquo;correct\u0026rdquo; record as seen in a strictly serializable history and the other shard holds the \u0026ldquo;incorrect\u0026rdquo; record. In this case the two transactions with inconsistent arrival order do not commute: one adds a property value to a relationship and one deletes that relationship.\nIt\u0026rsquo;s possible that a subsquent write might immediately correct this error with no side-effects, and it\u0026rsquo;s possible that the shard with the \u0026ldquo;correct\u0026rdquo; record might be read. But it\u0026rsquo;s also possible that the shard with the \u0026ldquo;incorrect\u0026rdquo; record will be read, and those incorrect values used to seed further writes, propagating the corruption around the graph. In general, there is no recovery from this corruption when it spreads. It\u0026rsquo;s often a coin toss as to which record is the correct one in the instant after it is written\nI\u0026rsquo;ll reiterate that: without any hardware or software failures, your data will be irreversibly garbage within its production lifetime. That\u0026rsquo;s a shocking result for a class of technology that has a degree of market buy-in.\nOur work has now been multiply peer reviewed and published, with the most recent analysis being in the Journal Queueing Models and Service Management.\nWhen is strongly consistent not strongly consistent? When it\u0026rsquo;s not consistently applied. Other entrants to the graph database market must have also seen the risks of eventual consistency for graphs have and opted to build their offerings atop strongly consistent models to avoid these pitfalls. The approach that I\u0026rsquo;ve seen in two databases (one closed source, one open) is to build strong guarantees into the replica sets (shards) that store the data. This is a very good starting point and is used in their marketing materials to give a sense of safety. Words like \u0026ldquo;ACID\u0026rdquo; and \u0026ldquo;strongly consistent\u0026rdquo; are used frequently to convey the safety properties of the systems.\nBut all is not well here. In fact, despite having better guarantees for consistency within a single replica set than eventually consistent databases, the same global ordering problem haunts these newer databases.\n// They fall foul of consistency within a shard and anything goes between shards.\nAcknowledgements The research work was made possible by a continuing joint effort between Newcastle University and Neo4j. Many thanks to my academic collaborators Paul Ezhilchelvan, Isi Mitrani, and Jack Waudby for entertaining my hunches and putting them on a solid academic foundation.\nMy colleage Hugo Firth (ex-Newcastle Ph.D., like me) provided a great deal of valuable feedback in writing up this piece as well as day to day sensible discussions on reliability in distributed systems.\nLike this? Want to get more involved? I\u0026rsquo;ll make a final pitch and remind you that Neo4j are hiring. So if you want to work with Hugo and me, then take a look at our open roles.\n","date":1606953647,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606953647,"objectID":"2a0859241cd9a3797804b49d5aad14f9","permalink":"/post/2020-12-weak-stong-consistency/","publishdate":"2020-12-03T00:00:47Z","relpermalink":"/post/2020-12-weak-stong-consistency/","section":"post","summary":"Thoughts on the design of distributed graph databases that use strongly consistent methods for the data stored on their shards, but pay no regard to ordering of concurrent updates.","tags":["graph databases","consistency"],"title":"Strong Consitency Claims in Distributed Graph Databases","type":"post"},{"authors":[],"categories":null,"content":"","date":1603202700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603202700,"objectID":"f5d229b9bac92e07ee86f1d7538afbe8","permalink":"/talk/2020-10-nodes/","publishdate":"2020-09-15T00:00:00Z","relpermalink":"/talk/2020-10-nodes/","section":"talk","summary":"Where we've been and where we're going with Neo4j's distributed, fault-tolerant algorithms.","tags":[],"title":"A Humane Presentation about Graph Database Internals","type":"talk"},{"authors":[],"categories":[],"content":"The old days: eventually-consistent graph databases I remember some years ago when the now abandoned TitanDB was launched thinking that its design was problematic. The driver for TitanDB, its successor in JanusGraph, and other similar graph databses was scale. I think it was a rational decision: the market was eager for scalability, and prized functionality like performance or latency far less. Of course this was - and still is - lazy thinking. Scale does not necessarily mean performant or high throughput, and often adds latency. Scale simply means you can add more computers to a system and hope to get some speedup for some use-cases.\nBut a particularly worrisome aspect about such eventually-consistent graph databases was their lack of safety. Eventual consistency is a straightforward guarantee that a replica set will converge to the same value eventually (perhaps even before the next read in good systems). The valued converged upon is influenced by the chosen concurrency control mechanisms (e.g. Last Writer Wins versus Logical Clocks etc), but nonetheless the guarantee is strictly for one replica set/shard. For what it\u0026rsquo;s worth, this is usually fine for many kinds of data, but it is not fine for graphs.\nSources of corruption in eventually-consistent graph databases With an eventually consistent distributed graph database there are two primary sources of potential corruption:\n The current transaction happens to read from a replica which is stale and uses that stale data to for updates. This is more complex than the same situation in a KV, document, or column store because graph database queries touch arbitrary keys and so undoing logical corruption is impractical and typically impossible. However, this is solvable with approaches like quorum reads though they will slow down the operation of the database considerably. Two transactions contend on a single relationship/egde which happens to span replica sets (shards from here on) and are applied in a mutually inconsistent order. This is also solvable but requires some functionality to impose ordering, which is expensive completely undermines eventual consistency, and so nobody does this because it implies transactions.  The TitanDB team were rigorous enough to call out this problem, but the language they used downplays its signficance. The documentation uses phrases like \u0026ldquo;temporary inconsistency\u0026rdquo; rather than \u0026ldquo;corruption that might be repaired, but might also cause further irreperable corruption\u0026rdquo; and \u0026ldquo;half edges\u0026rdquo; rather than \u0026ldquo;corrupted edge records\u0026rdquo;. While I don\u0026rsquo;t think this mollifying language has directly lead to a slew of copycat databases, it certainly set a tone for ignoring safety (which is still followed by JanusGraph, TitanDB\u0026rsquo;s fork and successor).\nQuantifying corruption in no-fault systems Unsatisfied with the unsafe status quo and ill-equipped to describe these problems to the broader market, I embarked upon some work with Paul Ezhilchelvan and Isi Mitrani at Newcastle University where we modelled a transactional workload on an abstract eventually-consistent distributed graph database.\nOur abstract model treats a graph database as a collection of replica sets each holding some fraction of the overall graph. Often the relationships (edges) between the nodes (vertices) are wholly held within a single shard, but around 30% of the time relationships join nodes across shards (based on my colleague Hugo Firth\u0026rsquo;s experience designing partitioning algorithms).\nOur abstract model allowed for write-after-stale-read from a replica as one source of corruption, and also allowed mutually out of order update processing for relationship records that span shards as the other primary source of corruption. Out of order updates have a chance of being overwritten correctly before they\u0026rsquo;re ever seen, but they also have a chance of the stale side of the relationship being read and used to compute future incorrect updates from where it becomes impossible to repair the data in the general case.\nIn our model, relationship records which cross shards are physically implemented as a two reciprocal records on each shard (a common real-world implementation strategy). That is if shard A has a node representing Rosa with an outgoing FOLLOWS relationship to a node representing Karl on shard B, then the Karl node on shard B should have an incoming FOLLOWS from Rosa on shard A.\n// TODO: picture needed\nEqually any properties on that relationship must be identical whether the relationship is traversed head to tail or tail to head.\n// TODO: picture needed\nWe term this reciprocal consistency and it is an invariant on the database so that data can be safely stored. Any deviation from a reciprocally consistent state is corruption, and that corruption has a chance to spread through the graph.\nUsing the model, we showed that for a billions-node scale-free graph and ~10,000 TPS and with some conservative estimates for the likelihood of transactions being applied mutually out of order, that the system would be garbage (defined as 10% corruption) in around 12-18 months.\nSince the model was computationally expensive (many hours of compute time needed for each minor parameter change) we used it to calibrate a computationally cheap numerical approximation which you can parameterise to see how your eventually consistent graph database might behave in production.\nI\u0026rsquo;ll reiterate that: without any hardware or software failures, your data will be irreversibly garbage within its production lifetime.\nThat\u0026rsquo;s a shocking result for a class of technology that has a degree of market buy-in.\nWhen is strongly consistent not strongly consistent? When it\u0026rsquo;s not consistently strong. Other entrants to the graph database market must have also seen the risks of eventual consistency for graphs have and opted to build their offerings atop strongly consistent models to avoid these pitfalls. The approach that I\u0026rsquo;ve seen in two databases (one closed source, one open) is to build strong guarantees into the replica sets (shards) that store the data. This is a very good starting point and is used in their marketing materials to give a sense of safety. Words like \u0026ldquo;ACID\u0026rdquo; and \u0026ldquo;strongly consistent\u0026rdquo; are used frequently to convey the safety properties of the systems.\nBut all is not well here. In fact, despite having better guarantees for consistency within a single replica set than eventually consistent databases, the same global ordering problem haunts these newer databases. Let\u0026rsquo;s assume that we have a database made from a number shards, and that each shard is magically completely fault tolerant and converges instantaneously for any update. These are obviously impossible characteristics, but it won\u0026rsquo;t change the outcome, I promise.\nThe problem is again of reciprocal consistency being undermined by race conditions in the presence of concurrent contented transactions. While we have fewer opportunities to read stale data in a single shard (because we assumed instant convergence), it\u0026rsquo;s still possible that transactions will be delivered mutually out of order to a pair of shards causing corruption which will then be read and used to propagate more corrupt writes around the graph.\nLet\u0026rsquo;s play this out. Consider two transactions T1 and T2 which both update a common cross-shard relationship R in some mutally incompatible manner. Drawing on the TitanDB example, this could be where one transaction tries to delete R while the other tries to update it.\nThere are two ways these transactions can achieve a consistent outcome and two ways in which they won\u0026rsquo;t, and since we don\u0026rsquo;t have any coordination logic to impose an ordering (presumably on the basis that it inhibits scalability) then we have to rely on natural arrival order and prayer.\n   Shard 1 Shard 2 Consistent     T1-\u0026gt;T2 T1-\u0026gt;T2 Yes   T2-\u0026gt;T1 T2-\u0026gt;T1 Yes   T2-\u0026gt;T1 T1-\u0026gt;T2 No   T1-\u0026gt;T2 T2-\u0026gt;T1 No    Corruption can occur when T1 and T2 are processed in different orders on different shards.\n// Reciprocal consistency violated\n","date":1600864727,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600864727,"objectID":"70f58ec28f4e8c78fb4fb4fd5c966663","permalink":"/post/2020-09-weak-stong-consistency/","publishdate":"2020-09-23T13:38:47+01:00","relpermalink":"/post/2020-09-weak-stong-consistency/","section":"post","summary":"Thoughts on the design of distributed graph databases that use strongly consistent methods for the data stored on their shards, but pay no regard to ordering of concurrent updates.","tags":["graph databases","consistency"],"title":"Strong Consitency Claims in Distributed Graph Databases","type":"post"},{"authors":[],"categories":[],"content":"Back in 2015 I bought a BMW i3 REX, and at the time had a 7kW charger charging socket fitted from ChargeMaster (now part of BP). It worked fine, and since the 2015 i3 has a small battery (~20kWh) full charges took just a few short hours. Wonderfully boring and predictable.\nFast forward to present day and the ChargeMaster socket repeatedly overheats and cuts out leaving me with potentially not enough charge for the day (ok, so there\u0026rsquo;s the range extender but that defeats the point). After a few calls to genuinely lovely people at BP ChargeMaster, we\u0026rsquo;re not getting anywhere fast. The warranty has expired and I never did talk to anyone - nice as they were - that I\u0026rsquo;d trust to wire a plug. But if I hand over another £500 I can get a replacement at some point.\n£500 for a socket - even a special, high-current, safety-concious socket is a lot of cash. So let\u0026rsquo;s look around first.\nMy first port of call was the Rolec sockets. Since this is a straight swap of like for like, it looked like a winner. It\u0026rsquo;s a few quid cheaper than the ChargeMaster kit too. Only problem is that electrical regulations have tightened up since my original socket was installed. The 18th edition regs require additional earthing to protect from the terrifying possibility of PEN faults on TN-C-S supplies. Installing an earth rod is a big undertaking, so what to do?\nEarth rods are not strictly required for indoor use (on the basis that you\u0026rsquo;re unlikely to sever the earth), but I\u0026rsquo;m conservative around mains electricity.\nAs it happens there is a more expensive but far better value EV charging socket available - the MyEnergi Zappi - which does not require an earth rod and has clever circuitry to detect PEN faults. It\u0026rsquo;s a couple of hundred quid more at ~£700 plus another few quid for associated smart gadgets. But this is easily made up for by the simple install and being 18th edition compliant without the cost and (surprising) complexity of correctly installing an earth rod.\nHaving received the Zappi, Harvi and Hub the installation was easy enough. In the Consumer Unit (\u0026ldquo;fuse box\u0026rdquo;), the existing 32A Type C MCB had to be replaced with a 32A B-curve MCB. This circuit on my CU happens to be RCD protected, but that\u0026rsquo;s not critical since the Zappi has RCD protection on the AC and DC circuits (18th edition regs again). My wiring was already present and suitable from the previous installation, 40A rated, wall-pinned and visually in excellent condition. It only needed 30-40cm of 10mm twin and earth from the existing junction box through the conduit and into the Zappi.\n  Zappi unit looks nice enough, for a garage anyway.   I recently bought a ferrule set and crimper after seeing one in use on a video by Artisan Electrics which really made the 10mm cable connections feel very robust. I would recommend this since they\u0026rsquo;re cheap to buy and easy to use.\nSo far so good - the electical work is very easy and because the charger has clever electronics, it\u0026rsquo;s just like wiring a regular domestic socket.\nOne of the nice things about the Zappi is that it\u0026rsquo;s \u0026ldquo;smart.\u0026rdquo; It can try to use on-site generation to charge your EV when there\u0026rsquo;s excess power. And even if there\u0026rsquo;s a heavy load on your main supply (I live in the UK, so single-phase supplies are very common for houses), it\u0026rsquo;ll adjust its power delivery so that the house as a whole never draws more the mains rating (100A for me).\n  Looks like I should plug the car in.   Zappi senses its electrical environment using current transformer (CT) clamps. Remembering A-level physics, the current passing along a conductor can induce a current in a nearby coil proportionally to the current flowing in the main conductor which can be (safely) measured. Zappi comes with a CT clamp and I used the Harvi which provides a wireless bridge from the CT clamp to the Zappi instead of running the cable across the ceiling of my garage.\nI hadn\u0026rsquo;t read the instructions well enough and there were two problems here:\n You have to tell Zappi that its internal CT1 is set to NONE. Then you have to nagivate to the Harvi device and set its CT1 to GRID. Ok, so took me a little while to fathom that, but got there. The bigger downside is that when using Harvi to wirelessly monitor the grid line, the maximum permissible mains current is 65A, which is 35A less than my mains rating (and indeed could supply a whole other charger). It\u0026rsquo;s not a problem for now, but adding a second EV and Zappi in the future could lead to slower and less predictable charging rates.  My solution to this will be to hardwire the grid CT clamp to the Zappi by running cable round the garage. I\u0026rsquo;ll then use a second CT clamp plus the Harvi (bought and paid for, so I have to put it to use) to monitor solar output. Solar monitoring is just a nerd thing so that I can see generation on the app: the Zappi does not use the solar CT clamp in its control algorithm.\nAll of this comes together in a nice app if you use the Hub, so you can see real-time use and program EV charging without having to be at the Zappi.\n  Hub sitting in a rat\u0026rsquo;s nest of wires with Google wifi. Don\u0026rsquo;t judge me.   I\u0026rsquo;m very impressed so far. Sure there were a couple of little gotchas while I learned my way around the menus, but otherwise a straightforward experience. Funelling excess solar into the car automatically is super nice, and the unit looks smart and is safe. The setup can also handle a static battery installation (with more CT clamps) and can prioritise whether EV or static battery storage gets excess solar power and it can also minimise using the battery to charge the car (which is very sensible).\n","date":1600678847,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600678847,"objectID":"967b4cf225ad9dcb6a484f1d24d4e132","permalink":"/post/2020-09-zappi-installation/","publishdate":"2020-09-21T10:00:47+01:00","relpermalink":"/post/2020-09-zappi-installation/","section":"post","summary":"Things learned installing a Zappi home EV charging socket.","tags":["zappi","EV"],"title":"Zappi Installation","type":"post"},{"authors":[],"categories":null,"content":"","date":1600180200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600180200,"objectID":"005da9b0cd5c269842752478e3036c94","permalink":"/talk/2020-09-connections/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/talk/2020-09-connections/","section":"talk","summary":"An overview of how graph databases can be used at all levels of government.","tags":[],"title":"Graphs in Government","type":"talk"},{"authors":[],"categories":[],"content":"I\u0026rsquo;ve just upgraded to the new modular Hugo static site builder and have taken the opportunity to smarten up a few things on my site. In the meantime I\u0026rsquo;m slowly migrating over some content like my publication record. Stay tuned.\n","date":1600173527,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600173527,"objectID":"3b38e84b67ec02998b14ff8313d21021","permalink":"/post/site-upgrade/","publishdate":"2020-09-15T13:38:47+01:00","relpermalink":"/post/site-upgrade/","section":"post","summary":"I\u0026rsquo;ve just upgraded to the new modular Hugo static site builder and have taken the opportunity to smarten up a few things on my site. In the meantime I\u0026rsquo;m slowly migrating over some content like my publication record.","tags":[],"title":"Site Upgrade","type":"post"},{"authors":["Paul Ezhilchelvan","Isi Mitrani","Jim Webber"],"categories":[],"content":"","date":1600161864,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600161864,"objectID":"2e2866f09407015e33e96ca63b5019a3","permalink":"/publication/2020-qmsm/","publishdate":"2020-09-15T10:24:24+01:00","relpermalink":"/publication/2020-qmsm/","section":"publication","summary":"Eventually consistent distribted graph databases corrupt data. This paper shows the rate at corruption leading to abandomment of a database and provides calibrated tools for reasoning about the spread of corruption in production databases.","tags":[],"title":"Modeling the Gradual Degradation of Eventually-Consistent Distributed Graph Databases","type":"publication"},{"authors":["Jim Webber and Rik van Bruggen"],"categories":[],"content":"","date":1600120194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600120194,"objectID":"012f8de40bf22bc99494f114e1714437","permalink":"/publication/graph-databases-for-dummies/","publishdate":"2020-09-14T22:49:54+01:00","relpermalink":"/publication/graph-databases-for-dummies/","section":"publication","summary":"A practice and humane introduction to graph databases and Neo4j, _Graph Databases For Dummies_ walks you through modeling, querying, and importing graph data, all the way through to your first production system.","tags":[],"title":"Graph Databases for Dummies","type":"publication"},{"authors":[],"categories":null,"content":"","date":1599689400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599689400,"objectID":"2d2c028d9af6ed14dab8d786b0830df0","permalink":"/talk/2020-09-yow/","publishdate":"2020-09-09T23:55:00+01:00","relpermalink":"/talk/2020-09-yow/","section":"talk","summary":"Where we've been and where we're going with distributed graph databases.","tags":[],"title":"A Humane Presentation about Graph Database Internals","type":"talk"},{"authors":[],"categories":null,"content":"","date":1595421900,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595421900,"objectID":"c7c2708d5818b738305d3dd076005e73","permalink":"/talk/2020-07-data-and-analytics-live/","publishdate":"2020-06-22T13:45:00+01:00","relpermalink":"/talk/2020-07-data-and-analytics-live/","section":"talk","summary":"Using graphs to provide a 360° view of your real-time data.","tags":[],"title":"360° View of Everything - How to Unlock the Power of Your Master Data using Graphs","type":"talk"},{"authors":["Jack Waudby","Paul Ezhilchelvan","Jim Webber","Isi Mitrani"],"categories":[],"content":"","date":1587979464,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587979464,"objectID":"102c145c0143797b89daffdb85ab1056","permalink":"/publication/2020-papoc/","publishdate":"2020-04-27T10:24:24+01:00","relpermalink":"/publication/2020-papoc/","section":"publication","summary":"Reciprocal consistency is at the heart of dependable distributed graph databases. This work examines methods for preserving reciprocal consistency and thus data correctness.","tags":[],"title":"Preserving reciprocal consistency in distributed graph databases","type":"publication"},{"authors":["Jonathan Sumrall","George H. L. Fletcher","Alexandra Poulovassilis","Johan Svensson","Magnus Vejlstrup","Chris Vest and Jim Webber"],"categories":[],"content":"","date":1471944264,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471944264,"objectID":"65782ecd1aa72313de34ee7bd70c59e6","permalink":"/publication/2016-pelga/","publishdate":"2016-08-23T10:24:24+01:00","relpermalink":"/publication/2016-pelga/","section":"publication","summary":"Results of an investigation into path indexing for graph databases.","tags":[],"title":"Investigations on path indexing for graph databases","type":"publication"},{"authors":["Ian Robinson","Jim Webber","and Emil Eifrem"],"categories":[],"content":"","date":1433842246,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433842246,"objectID":"e6d74f37bf5f59c2177fa2ab2f68a92a","permalink":"/publication/graph-databases/","publishdate":"2015-06-09T10:30:46+01:00","relpermalink":"/publication/graph-databases/","section":"publication","summary":"The first book on graph databases, now in its second edition. Provides in-depth coverage of graph modeling and querying, as well as thorough explanations of the internal workings of Neo4j.","tags":[],"title":"Graph Databases","type":"publication"},{"authors":["Jim Webber","Savas Parastatidis","Ian Robinson"],"categories":[],"content":"","date":1285579988,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1285579988,"objectID":"2db9f55ef220f36533b80ec38f5b0c94","permalink":"/publication/rest-in-practice/","publishdate":"2010-09-27T10:33:08+01:00","relpermalink":"/publication/rest-in-practice/","section":"publication","summary":"Why don't typical enterprise projects go as smoothly as projects you develop for the Web? Does the REST architectural style really present a viable alternative for building distributed systems and enterprise-class applications? In this insightful book, three SOA experts provide a down-to-earth explanation of REST and demonstrate how you can develop simple and elegant distributed hypermedia systems by applying the Web's guiding principles to common enterprise computing problems. You'll learn techniques for implementing specific Web technologies and patterns to solve the needs of a typical company as it grows from modest beginnings to become a global enterprise.","tags":[],"title":"Rest in Practice","type":"publication"},{"authors":["Emerson Ribeiro De Mello","Savas Parastatidis","Philipp Reinecke","Chris Smith","Aad van Moorsel","and Jim Webber"],"categories":[],"content":"","date":1158571464,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1158571464,"objectID":"dbbf72d6161e59cd41544db224d49f5d","permalink":"/publication/2006-ieee-scc/","publishdate":"2006-09-18T10:24:24+01:00","relpermalink":"/publication/2006-ieee-scc/","section":"publication","summary":"A realistic workflow appliation for real-estate using SSDL to reason about correctness of multiparty protocols over the Internet.","tags":[],"title":"Secure and Provable Service Support for Human-Intensive Real-Estate Processes","type":"publication"},{"authors":["Jen-Yao Chung","George Feuerlicht","and Jim Webber (Eds.)"],"categories":[],"content":"","date":1134379464,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1134379464,"objectID":"5ab061b53aaae5bfc0648ad4c4da5b4b","permalink":"/publication/2005-wdsoa/","publishdate":"2004-09-15T10:24:24+01:00","relpermalink":"/publication/2005-wdsoa/","section":"publication","summary":"Organising and editing the proceedings of a workshop on the design of service-oriented systems alongside ICSOC 2005.","tags":[],"title":"First International Workshop on Design of Service-Oriented Applications (WDSOA'05)","type":"publication"},{"authors":["Savas Parastatidis and Jim Webber"],"categories":[],"content":"","date":1095240264,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1095240264,"objectID":"f163d804ce861c76154bf4c944cb2688","permalink":"/publication/2004-ieee-scc/","publishdate":"2004-09-15T10:24:24+01:00","relpermalink":"/publication/2004-ieee-scc/","section":"publication","summary":"A framework for reasoning about an immature and chaotic set of protocols and standards for building potentially long-lived systems.","tags":[],"title":"Assessing the Risk and Value of Adopting Emerging and Unstable Web Services Specifications","type":"publication"},{"authors":["Savas Parastatidis","Paul Watson","and Jim Webber"],"categories":[],"content":"","date":1088069064,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1088069064,"objectID":"4ea79eb23af38d9323f7cb9f9b9ed95d","permalink":"/publication/2004-delos/","publishdate":"2004-06-24T10:24:24+01:00","relpermalink":"/publication/2004-delos/","section":"publication","summary":"Showing how large-scale Grid computing designed as a service-oriented architecture and implemented by standard Web Services.","tags":[],"title":"Grid Computing using Web Services Technologies","type":"publication"},{"authors":["Savas Parastatidis and Jim Webber"],"categories":[],"content":"","date":1086427464,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1086427464,"objectID":"3b7e4d7db6edfa88d7d8f40567365849","permalink":"/publication/2004-ggf/","publishdate":"2004-06-05T10:24:24+01:00","relpermalink":"/publication/2004-ggf/","section":"publication","summary":"The WS-GAF Registry Service is a naming and metadata service which allows clients to late bind (in a limited fashion) to services as part of a larger grid application.","tags":[],"title":"The WS-GAF Registry Service","type":"publication"},{"authors":["Sandeep Chatterjee and Jim Webber"],"categories":[],"content":"","date":1068804065,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1068804065,"objectID":"b4cd62469174a27b44a6b9937da6df10","permalink":"/publication/developing-enterprise-web-services/","publishdate":"2003-11-14T11:01:05+01:00","relpermalink":"/publication/developing-enterprise-web-services/","section":"publication","summary":"This was one of the first books to demonstrate how to build (WS-*) Web Services with enterprise-class reliability, and performance. This book takes a no-nonsense view of architecting and constructing enterprise-class Web services and applications. The authors assess the state of the art of the Web services platform circa 2004, offering best practices and new architectural patterns for taking advantage of Web Services. _While the architectural patterns in this book generally remain worthwhile today, the protocols and standards covered are now looking somewhat out of date, especially since there is a strong groundswell towards building RESTful systems on the Web rather than tunnelling through HTTP with XML payloads._","tags":[],"title":"Developing Enterprise Web Services","type":"publication"},{"authors":["Lindsay Marshall and Jim Webber"],"categories":[],"content":"","date":1024392264,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1024392264,"objectID":"ec947253e5ff0dd69d476af66e2d6480","permalink":"/publication/2002-ppig/","publishdate":"2002-06-18T10:24:24+01:00","relpermalink":"/publication/2002-ppig/","section":"publication","summary":"Thinking about how programmers interact, the stories they tell, and how they impact software engineering.","tags":[],"title":"The Misplaced Comma: Programmers’ Tales and Traditions","type":"publication"},{"authors":["Jim Webber and P.A. Lee"],"categories":[],"content":"","date":968577864,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":968577864,"objectID":"ce300b77a4df5186aa1248a760f61e88","permalink":"/publication/2000-ieee-visual-languages/","publishdate":"2000-09-10T10:24:24+01:00","relpermalink":"/publication/2000-ieee-visual-languages/","section":"publication","summary":"The Vorlon hybrid textual-visual parallel programming language.","tags":[],"title":"Visual, Object-Oriented Development of Parallel Applications","type":"publication"},{"authors":["Lindsay Marshall and Jim Webber"],"categories":[],"content":"","date":955358664,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":955358664,"objectID":"7590b81462668f80e2b1283c3a1a80c9","permalink":"/publication/2000-ppig/","publishdate":"2000-04-10T10:24:24+01:00","relpermalink":"/publication/2000-ppig/","section":"publication","summary":"Thinking about programmers' susperstitions and taboos and the effects they have on software development.","tags":[],"title":"Gotos Considered Harmful and Other Programmers' Taboos","type":"publication"}]